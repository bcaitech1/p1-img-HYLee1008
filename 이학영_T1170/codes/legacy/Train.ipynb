{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocational-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brilliant-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# csv files\n",
    "train_csv = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "test_csv = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "\n",
    "# image directories\n",
    "train_image_dir = os.path.join(train_dir, 'images')\n",
    "test_image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "train_image_paths = [os.path.join(train_image_dir, img_id) for img_id in train_csv.path]\n",
    "test_image_paths = [os.path.join(test_image_dir, img_id) for img_id in test_csv.ImageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grave-lightweight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define train datset & test datset class\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, csv, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.csv = csv\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get persion id and mask info\n",
    "        pid, mask_id = divmod(index, 7)\n",
    "        \n",
    "        # get image\n",
    "        mask_images = [d for d in os.listdir(self.img_paths[pid]) if not d.startswith('._')]\n",
    "        image = Image.open(os.path.join(self.img_paths[pid], mask_images[mask_id]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        #get label info\n",
    "        gender = 0 if self.csv.gender[pid] == 'male' else 1\n",
    "        age = 0 if self.csv.age[pid] < 30 else 1 if 30 <= self.csv.age[pid] < 60 else 2\n",
    "        mask = 1 if 'incorrect' in mask_images[mask_id] else 2 if 'normal' in mask_images[mask_id] else 0\n",
    "        \n",
    "        label = 6 * mask + 3 * gender + age\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths) * 7\n",
    "    \n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varied-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "train_dataset = TrainDataset(train_image_paths, train_csv, transform)\n",
    "test_dataset = TestDataset(test_image_paths, transform)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alternate-honduras",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Epoch #0 train_acc: 84.82142857142857, valid_acc: 86.11111111111111\n",
      "[Fold 1] Epoch #1 train_acc: 95.13227513227513, valid_acc: 85.7936507936508\n",
      "[Fold 1] Epoch #2 train_acc: 96.42857142857143, valid_acc: 81.29629629629629\n",
      "[Fold 1] Epoch #3 train_acc: 97.31481481481481, valid_acc: 82.46031746031746\n",
      "[Fold 1] Epoch #4 train_acc: 97.3478835978836, valid_acc: 79.62962962962963\n",
      "[Fold 1] Epoch #5 train_acc: 97.5, valid_acc: 79.81481481481481\n",
      "[Fold 1] Epoch #6 train_acc: 97.91005291005291, valid_acc: 82.4074074074074\n",
      "[Fold 1] Epoch #7 train_acc: 97.92328042328042, valid_acc: 83.46560846560847\n",
      "[Fold 1] Epoch #8 train_acc: 97.90343915343915, valid_acc: 80.8994708994709\n",
      "[Fold 1] Epoch #9 train_acc: 97.98280423280423, valid_acc: 61.34920634920635\n",
      "[Fold 2] Epoch #0 train_acc: 96.0515873015873, valid_acc: 95.8994708994709\n",
      "[Fold 2] Epoch #1 train_acc: 97.7579365079365, valid_acc: 94.92063492063492\n",
      "[Fold 2] Epoch #2 train_acc: 98.11507936507937, valid_acc: 92.77777777777777\n",
      "[Fold 2] Epoch #3 train_acc: 98.35317460317461, valid_acc: 94.47089947089947\n",
      "[Fold 2] Epoch #4 train_acc: 98.01587301587301, valid_acc: 92.11640211640211\n",
      "[Fold 2] Epoch #5 train_acc: 98.5978835978836, valid_acc: 91.4021164021164\n",
      "[Fold 2] Epoch #6 train_acc: 98.41931216931216, valid_acc: 89.76190476190476\n",
      "[Fold 2] Epoch #7 train_acc: 98.68386243386243, valid_acc: 91.13756613756614\n",
      "[Fold 2] Epoch #8 train_acc: 98.94179894179894, valid_acc: 90.31746031746032\n",
      "[Fold 2] Epoch #9 train_acc: 98.52513227513228, valid_acc: 88.0952380952381\n",
      "[Fold 3] Epoch #0 train_acc: 96.09126984126983, valid_acc: 97.85714285714286\n",
      "[Fold 3] Epoch #1 train_acc: 98.51190476190476, valid_acc: 95.7936507936508\n",
      "[Fold 3] Epoch #2 train_acc: 98.80952380952381, valid_acc: 96.77248677248677\n",
      "[Fold 3] Epoch #3 train_acc: 98.79629629629629, valid_acc: 91.85185185185185\n",
      "[Fold 3] Epoch #4 train_acc: 98.35317460317461, valid_acc: 94.60317460317461\n",
      "[Fold 3] Epoch #5 train_acc: 98.5515873015873, valid_acc: 88.94179894179894\n",
      "[Fold 3] Epoch #6 train_acc: 98.89550264550265, valid_acc: 93.78306878306879\n",
      "[Fold 3] Epoch #7 train_acc: 99.12698412698413, valid_acc: 92.72486772486772\n",
      "[Fold 3] Epoch #8 train_acc: 99.16005291005291, valid_acc: 94.44444444444444\n",
      "[Fold 3] Epoch #9 train_acc: 98.67063492063492, valid_acc: 91.16402116402116\n",
      "[Fold 4] Epoch #0 train_acc: 98.19444444444444, valid_acc: 97.35449735449735\n",
      "[Fold 4] Epoch #1 train_acc: 99.08068783068784, valid_acc: 94.2063492063492\n",
      "[Fold 4] Epoch #2 train_acc: 99.14021164021165, valid_acc: 89.33862433862434\n",
      "[Fold 4] Epoch #3 train_acc: 98.96825396825396, valid_acc: 92.85714285714286\n",
      "[Fold 4] Epoch #4 train_acc: 99.51719576719577, valid_acc: 85.21164021164022\n",
      "[Fold 4] Epoch #5 train_acc: 98.93518518518519, valid_acc: 83.35978835978835\n",
      "[Fold 4] Epoch #6 train_acc: 99.47089947089947, valid_acc: 84.76190476190476\n",
      "[Fold 4] Epoch #7 train_acc: 99.06746031746032, valid_acc: 87.56613756613757\n",
      "[Fold 4] Epoch #8 train_acc: 99.23941798941799, valid_acc: 81.13756613756614\n",
      "[Fold 4] Epoch #9 train_acc: 99.43783068783068, valid_acc: 82.77777777777777\n",
      "[Fold 5] Epoch #0 train_acc: 96.46825396825396, valid_acc: 96.7989417989418\n",
      "[Fold 5] Epoch #1 train_acc: 98.62433862433862, valid_acc: 96.77248677248677\n",
      "[Fold 5] Epoch #2 train_acc: 99.17328042328042, valid_acc: 98.57142857142857\n",
      "[Fold 5] Epoch #3 train_acc: 99.39153439153439, valid_acc: 98.06878306878306\n",
      "[Fold 5] Epoch #4 train_acc: 99.36507936507937, valid_acc: 96.87830687830687\n",
      "[Fold 5] Epoch #5 train_acc: 99.06084656084656, valid_acc: 96.29629629629629\n",
      "[Fold 5] Epoch #6 train_acc: 99.2526455026455, valid_acc: 92.93650793650794\n",
      "[Fold 5] Epoch #7 train_acc: 99.47751322751323, valid_acc: 96.11111111111111\n",
      "[Fold 5] Epoch #8 train_acc: 98.80291005291005, valid_acc: 95.18518518518519\n",
      "[Fold 5] Epoch #9 train_acc: 99.44444444444444, valid_acc: 96.45502645502646\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.00005, weight_decay=0.01)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(train_dataset), 1):    \n",
    "    train_sub = Subset(train_dataset, train_index)\n",
    "    valid_sub = Subset(train_dataset, valid_index)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_sub,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_sub,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for images, labels in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                output = model(images)\n",
    "                _, predicted = output.max(1)\n",
    "                valid_total += labels.size(0)\n",
    "                valid_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "\n",
    "        # update the learning rate\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        print(f\"[Fold {fold}] Epoch #{epoch} train_acc: {100.*train_correct/train_total}, valid_acc: {100.*valid_correct/valid_total}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "voluntary-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "PATH = 'model_9.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-motor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
