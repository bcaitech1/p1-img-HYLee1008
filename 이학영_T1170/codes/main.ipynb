{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complicated-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import albumentations\n",
    "# from albumentations.pytorch import ToTensor\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from src.train import train\n",
    "from src.inference import inference\n",
    "from src.evaluation import evaluate\n",
    "from src.model import Net\n",
    "from src.loss import my_loss\n",
    "from src.dataset import TrainDataset, TestDataset, get_train_dataloader, get_valid_dataloader, get_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pediatric-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "model_num = 1\n",
    "MODEL_PATH = os.path.join('./models/', datetime.datetime.now().strftime('%Y-%m-%d') + f' model {model_num}')\n",
    "submission_file_name = datetime.datetime.now().strftime('%Y-%m-%d') + f' model {model_num}.csv'\n",
    "pathlib.Path(MODEL_PATH).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "learning_rate = 0.00005\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# csv files\n",
    "train_csv = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "test_csv = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "\n",
    "# image directories\n",
    "train_image_dir = os.path.join(train_dir, 'images')\n",
    "test_image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "train_image_paths = [os.path.join(train_image_dir, img_id) for img_id in train_csv.path]\n",
    "test_image_paths = [os.path.join(test_image_dir, img_id) for img_id in test_csv.ImageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operational-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformer\n",
    "train_transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "# train_transform = albumentations.Compose([\n",
    "#     albumentations.Resize(512, 384), \n",
    "# #     albumentations.HorizontalFlip(0.5),\n",
    "#     ToTensor(),\n",
    "#     albumentations.Normalize(mean=(0.5,), std=(0.2,))\n",
    "# ])\n",
    "\n",
    "# test_transform = albumentations.Compose([\n",
    "#     albumentations.Resize(512, 384),\n",
    "#     ToTensor(),\n",
    "#     albumentations.Normalize(mean=(0.5,), std=(0.2,))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "understanding-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train, test dataset\n",
    "train_dataset = TrainDataset(train_image_paths, train_csv, train_transform)\n",
    "test_dataset = TestDataset(test_image_paths, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "popular-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Epoch #0 train_acc: 85.07, valid_acc: 80.50\n",
      "model saved at [fold 1] Epoch #0\n",
      "[Fold 1] Epoch #1 train_acc: 96.12, valid_acc: 80.08\n",
      "[Fold 1] Epoch #2 train_acc: 97.71, valid_acc: 82.51\n",
      "model saved at [fold 1] Epoch #2\n",
      "[Fold 1] Epoch #3 train_acc: 98.01, valid_acc: 80.45\n",
      "[Fold 1] Epoch #4 train_acc: 97.98, valid_acc: 79.23\n",
      "[Fold 1] Epoch #5 train_acc: 98.02, valid_acc: 77.17\n",
      "[Fold 1] Epoch #6 train_acc: 98.36, valid_acc: 82.49\n",
      "[Fold 1] Epoch #7 train_acc: 98.31, valid_acc: 78.84\n",
      "[Fold 1] Epoch #8 train_acc: 98.66, valid_acc: 82.75\n",
      "model saved at [fold 1] Epoch #8\n",
      "[Fold 1] Epoch #9 train_acc: 98.28, valid_acc: 81.61\n",
      "[Fold 1] Epoch #10 train_acc: 98.72, valid_acc: 84.23\n",
      "model saved at [fold 1] Epoch #10\n",
      "[Fold 1] Epoch #11 train_acc: 98.49, valid_acc: 80.82\n",
      "[Fold 1] Epoch #12 train_acc: 98.31, valid_acc: 83.54\n",
      "[Fold 1] Epoch #13 train_acc: 99.35, valid_acc: 83.54\n",
      "[Fold 1] Epoch #14 train_acc: 98.59, valid_acc: 83.84\n",
      "[Fold 2] Epoch #0 train_acc: 85.56, valid_acc: 78.36\n",
      "[Fold 2] Epoch #1 train_acc: 96.36, valid_acc: 85.50\n",
      "model saved at [fold 2] Epoch #1\n",
      "[Fold 2] Epoch #2 train_acc: 97.74, valid_acc: 86.11\n",
      "model saved at [fold 2] Epoch #2\n",
      "[Fold 2] Epoch #3 train_acc: 97.94, valid_acc: 71.72\n",
      "[Fold 2] Epoch #4 train_acc: 98.18, valid_acc: 85.11\n",
      "[Fold 2] Epoch #5 train_acc: 97.94, valid_acc: 81.90\n",
      "[Fold 2] Epoch #6 train_acc: 98.47, valid_acc: 84.18\n",
      "[Fold 2] Epoch #7 train_acc: 97.96, valid_acc: 81.72\n",
      "[Fold 2] Epoch #8 train_acc: 98.85, valid_acc: 82.96\n",
      "[Fold 2] Epoch #9 train_acc: 97.92, valid_acc: 79.95\n",
      "[Fold 2] Epoch #10 train_acc: 98.49, valid_acc: 83.92\n",
      "[Fold 2] Epoch #11 train_acc: 98.66, valid_acc: 85.63\n",
      "[Fold 2] Epoch #12 train_acc: 98.68, valid_acc: 82.94\n",
      "[Fold 2] Epoch #13 train_acc: 98.66, valid_acc: 83.15\n",
      "[Fold 2] Epoch #14 train_acc: 99.04, valid_acc: 85.19\n",
      "[Fold 3] Epoch #0 train_acc: 85.12, valid_acc: 80.26\n",
      "[Fold 3] Epoch #1 train_acc: 96.14, valid_acc: 88.97\n",
      "model saved at [fold 3] Epoch #1\n",
      "[Fold 3] Epoch #2 train_acc: 97.41, valid_acc: 82.80\n",
      "[Fold 3] Epoch #3 train_acc: 98.14, valid_acc: 88.70\n",
      "[Fold 3] Epoch #4 train_acc: 98.17, valid_acc: 75.90\n",
      "[Fold 3] Epoch #5 train_acc: 97.94, valid_acc: 85.11\n",
      "[Fold 3] Epoch #6 train_acc: 98.25, valid_acc: 87.54\n",
      "[Fold 3] Epoch #7 train_acc: 98.29, valid_acc: 89.10\n",
      "model saved at [fold 3] Epoch #7\n",
      "[Fold 3] Epoch #8 train_acc: 98.41, valid_acc: 89.23\n",
      "model saved at [fold 3] Epoch #8\n",
      "[Fold 3] Epoch #9 train_acc: 98.38, valid_acc: 87.91\n",
      "[Fold 3] Epoch #10 train_acc: 98.51, valid_acc: 81.98\n",
      "[Fold 3] Epoch #11 train_acc: 98.74, valid_acc: 87.54\n",
      "[Fold 3] Epoch #12 train_acc: 98.23, valid_acc: 87.06\n",
      "[Fold 3] Epoch #13 train_acc: 98.79, valid_acc: 83.17\n",
      "[Fold 3] Epoch #14 train_acc: 98.58, valid_acc: 87.65\n",
      "[Fold 4] Epoch #0 train_acc: 87.67, valid_acc: 76.16\n",
      "[Fold 4] Epoch #1 train_acc: 96.81, valid_acc: 71.14\n",
      "[Fold 4] Epoch #2 train_acc: 98.02, valid_acc: 75.29\n",
      "[Fold 4] Epoch #3 train_acc: 98.13, valid_acc: 70.37\n",
      "[Fold 4] Epoch #4 train_acc: 98.24, valid_acc: 73.33\n",
      "[Fold 4] Epoch #5 train_acc: 98.37, valid_acc: 75.05\n",
      "[Fold 4] Epoch #6 train_acc: 98.24, valid_acc: 75.32\n",
      "[Fold 4] Epoch #7 train_acc: 98.67, valid_acc: 73.89\n",
      "[Fold 4] Epoch #8 train_acc: 98.31, valid_acc: 70.82\n",
      "[Fold 4] Epoch #9 train_acc: 98.47, valid_acc: 73.15\n",
      "[Fold 4] Epoch #10 train_acc: 98.76, valid_acc: 76.85\n",
      "[Fold 4] Epoch #11 train_acc: 99.02, valid_acc: 73.41\n",
      "[Fold 4] Epoch #12 train_acc: 98.39, valid_acc: 73.28\n",
      "[Fold 4] Epoch #13 train_acc: 99.25, valid_acc: 75.77\n",
      "[Fold 4] Epoch #14 train_acc: 98.35, valid_acc: 77.72\n",
      "[Fold 5] Epoch #0 train_acc: 84.64, valid_acc: 91.14\n",
      "model saved at [fold 5] Epoch #0\n",
      "[Fold 5] Epoch #1 train_acc: 96.20, valid_acc: 80.13\n",
      "[Fold 5] Epoch #2 train_acc: 97.59, valid_acc: 83.57\n",
      "[Fold 5] Epoch #3 train_acc: 97.94, valid_acc: 76.53\n",
      "[Fold 5] Epoch #4 train_acc: 97.88, valid_acc: 85.90\n",
      "[Fold 5] Epoch #5 train_acc: 98.17, valid_acc: 87.70\n",
      "[Fold 5] Epoch #6 train_acc: 98.18, valid_acc: 88.31\n",
      "[Fold 5] Epoch #7 train_acc: 98.17, valid_acc: 86.88\n",
      "[Fold 5] Epoch #8 train_acc: 98.42, valid_acc: 78.39\n",
      "[Fold 5] Epoch #9 train_acc: 98.47, valid_acc: 88.20\n",
      "[Fold 5] Epoch #10 train_acc: 98.52, valid_acc: 84.23\n",
      "[Fold 5] Epoch #11 train_acc: 98.33, valid_acc: 85.66\n",
      "[Fold 5] Epoch #12 train_acc: 98.75, valid_acc: 80.03\n",
      "[Fold 5] Epoch #13 train_acc: 98.80, valid_acc: 85.37\n",
      "[Fold 5] Epoch #14 train_acc: 98.58, valid_acc: 69.44\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset with KFold and train\n",
    "kfold = KFold(n_splits=5)\n",
    "criterion = my_loss()\n",
    "\n",
    "max_acc = 0\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(train_dataset), 1):    \n",
    "    train_sub = Subset(train_dataset, train_index)\n",
    "    valid_sub = Subset(train_dataset, valid_index)\n",
    "    \n",
    "    train_loader = get_train_dataloader(train_sub, batch_size, num_workers)\n",
    "    valid_loader = get_valid_dataloader(valid_sub, batch_size, num_workers)\n",
    "    \n",
    "    # Create model\n",
    "    model = Net()\n",
    "    model.to(device)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=weight_decay)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    lr_scheduler = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct, train_total = train(model, train_loader, optimizer, criterion, device)\n",
    "        valid_correct, valid_total = inference(model, valid_loader, device)\n",
    "        \n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        valid_acc = 100.*valid_correct/valid_total\n",
    "        \n",
    "        print(f\"[Fold {fold}] Epoch #{epoch} train_acc: {train_acc:.2f}, valid_acc: {valid_acc:.2f}\")\n",
    "        \n",
    "        if max_acc < valid_acc:\n",
    "            final_path = os.path.join(MODEL_PATH, f'fold_{fold}_epoch_{epoch}_model.pth')\n",
    "            torch.save(model.state_dict(), final_path)\n",
    "            print(f'model saved at [fold {fold}] Epoch #{epoch}')\n",
    "            max_acc = valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sporting-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "# final_path = './models/2021-04-01 model 1/fold_5_epoch_9_model.pth'\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(final_path))\n",
    "model.to(device)\n",
    "\n",
    "test_loader = get_test_dataloader(test_dataset)\n",
    "evaluate(model, test_loader, test_csv, test_dir, submission_file_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
